# Am I(AI) Biased

**Am I(AI) Biased** is a research-based project focused on exploring and identifying bias in large language models (LLMs).  
The goal is to understand how models interpret, generate, and possibly reinforce biased patterns through their responses.  
This project combines hands-on testing of models with academic research to uncover how bias appears and what methods exist to detect or reduce it.

---

## Overview

This project is divided into multiple sprints:

### Sprint 1
- Experimented with different LLMs (`Llama-3.2-1B`, `Llama-3.2-3B`, and `Phi-3.5-mini-instruct`) to understand how they process inputs and generate text.
- Learned about tokenization and model reasoning.
- Documented examples of model strengths, weaknesses, and limitations.

### Sprint 2
- Focused on researching academic papers and articles about bias in AI systems.
- Identified common themes, methods for measuring bias, and real-world examples of how bias appears in AI.

---

## Project Goals

- Understand how tokenization and model training affect bias and fairness.  
- Compare outputs from different language models to see where bias might appear.  
- Research existing studies on AI bias and summarize key insights.  
- Build awareness around the ethical and societal impacts of biased AI systems.

---

## Technologies Used

- **Python**
- **Google Colab** â€“ for running and testing models  
- **Transformers (Hugging Face)** â€“ for loading and generating text from models  
- **PyTorch** â€“ for model computation

---

## Models Explored

- `meta-llama/Llama-3.2-1B`
- `meta-llama/Llama-3.2-3B`
- `microsoft/Phi-3.5-mini-instruct`

---

## Current Focus

Researching and documenting findings on AI bias, including reviewing recent academic papers that discuss bias detection, evaluation, and mitigation techniques in large language models.

---

## Future Plans

- Create structured test prompts to analyze biased outputs in different models.  
- Compare model behaviors across demographic, cultural, and linguistic variations.  
- Summarize findings in a final presentation or report for the capstone showcase.

---

## ðŸ“š Authors

**Michelle Duong, Jason Tran, AaJanae Henry**  
Pacific University â€“ B.S. in Computer Science (Expected Graduation: May 2026)
